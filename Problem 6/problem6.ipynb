{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4328d022-1f8d-442f-921e-d16693058a4c",
   "metadata": {},
   "source": [
    "Here, we will solve problems two ways\n",
    "1. First using PySpark function \n",
    "2. Second using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4647c5-df06-4d53-b4b4-66677cc54ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Load all the required library and also Start Spark Session\n",
    "# Load all the required library\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fdceb9-20df-4588-8820-672d48778b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/02/14 14:24:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Start Spark Session\n",
    "spark = SparkSession.builder.appName(\"problem6\").getOrCreate()\n",
    "sqlContext = SparkSession(spark)\n",
    "#Dont Show warning only error\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ec58af-280e-4eef-a95e-308df1bcbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV file into DataFrame\n",
    "studentdf = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6604a74-b1f5-49e5-a593-f35ca2417030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Marks: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check Schema of DataFrame\n",
    "studentdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47481142-ee32-401e-a481-03b3dd5b80ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+\n",
      "| ID|     Name|Marks|\n",
      "+---+---------+-----+\n",
      "| 19| Samantha|   87|\n",
      "| 21|    Julia|   96|\n",
      "| 11|  Britney|   95|\n",
      "| 32| Kristeen|  100|\n",
      "| 12|    Dyana|   55|\n",
      "| 13|    Jenny|   66|\n",
      "| 14|Christene|   88|\n",
      "| 15|    Meera|   24|\n",
      "| 16|    Priya|   76|\n",
      "| 17| Priyanka|   77|\n",
      "| 18|    Paige|   74|\n",
      "| 19|     Jane|   64|\n",
      "| 21|   Belvet|   78|\n",
      "| 31|  Scarlet|   80|\n",
      "| 41|    Salma|   81|\n",
      "| 51|   Amanda|   34|\n",
      "| 61|  Heraldo|   94|\n",
      "| 71|   Stuart|   99|\n",
      "| 81|   Aamina|   77|\n",
      "| 76|    Amina|   89|\n",
      "+---+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check sample Data \n",
    "studentdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc98254-6248-4cd6-af15-bb4b5a832171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     Name|\n",
      "+---------+\n",
      "|   Stuart|\n",
      "| Kristeen|\n",
      "|Christene|\n",
      "|    Amina|\n",
      "|   Aamina|\n",
      "|    Priya|\n",
      "|  Heraldo|\n",
      "|  Scarlet|\n",
      "|    Julia|\n",
      "|    Salma|\n",
      "|  Britney|\n",
      "| Priyanka|\n",
      "| Samantha|\n",
      "|    Vivek|\n",
      "|   Belvet|\n",
      "|    Devil|\n",
      "|     Evil|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Solving Problem using PySpark \n",
    "#Filter with Markes > 75 and then order by last 3 char and ID\n",
    "from pyspark.sql.functions import expr\n",
    "studentdf.select(\"Name\").where(\"Marks > 75\").orderBy(expr(\"RIGHT(Name,3)\"),\"ID\").show(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c28f990b-7e88-4c88-bd36-ca17a83544c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are solving Same problem using Spark SQL \n",
    "# Creating Temp Table or HIVE table\n",
    "stationdf.createOrReplaceTempView(\"tmpStudent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a48a300-9f44-4321-a138-942e6f1daf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     Name|\n",
      "+---------+\n",
      "|   Stuart|\n",
      "| Kristeen|\n",
      "|Christene|\n",
      "|    Amina|\n",
      "|   Aamina|\n",
      "|    Priya|\n",
      "|  Heraldo|\n",
      "|  Scarlet|\n",
      "|    Julia|\n",
      "|    Salma|\n",
      "|  Britney|\n",
      "| Priyanka|\n",
      "| Samantha|\n",
      "|    Vivek|\n",
      "|   Belvet|\n",
      "|    Devil|\n",
      "|     Evil|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we have SQL Table and we can write SQL Query on top of that \n",
    "# For example by Select on table \n",
    "sqlContext.sql(\"SELECT Name \\\n",
    "                    FROM tmpStudent \\\n",
    "                    WHERE Marks > 75 \\\n",
    "                    ORDER BY right(Name,3),ID\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
