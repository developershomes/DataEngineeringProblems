{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4328d022-1f8d-442f-921e-d16693058a4c",
   "metadata": {},
   "source": [
    "Here, we will solve problems two ways\n",
    "1. First using PySpark function \n",
    "2. Second using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4647c5-df06-4d53-b4b4-66677cc54ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Load all the required library and also Start Spark Session\n",
    "# Load all the required library\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fdceb9-20df-4588-8820-672d48778b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/02/08 11:06:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Start Spark Session\n",
    "spark = SparkSession.builder.appName(\"problem2\").getOrCreate()\n",
    "sqlContext = SparkSession(spark)\n",
    "#Dont Show warning only error\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ec58af-280e-4eef-a95e-308df1bcbf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Load CSV file into DataFrame\n",
    "employeedf = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"employee_salary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6604a74-b1f5-49e5-a593-f35ca2417030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check Schema of DataFrame\n",
    "employeedf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47481142-ee32-401e-a481-03b3dd5b80ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+\n",
      "| id|first_name|last_name|salary|department_id|\n",
      "+---+----------+---------+------+-------------+\n",
      "| 45|     Kevin|   Duncan| 45210|         1003|\n",
      "| 25|    Pamela| Matthews| 57944|         1005|\n",
      "| 48|    Robert|    Lynch|117960|         1004|\n",
      "| 34|    Justin|     Dunn| 67992|         1003|\n",
      "| 62|      Dale|    Hayes| 97662|         1005|\n",
      "|  1|      Todd|   Wilson|110000|         1006|\n",
      "| 61|      Ryan|    Brown|120000|         1003|\n",
      "| 21|   Stephen|    Berry|123617|         1002|\n",
      "| 13|     Julie|  Sanchez|210000|         1001|\n",
      "| 55|   Michael|   Morris|106799|         1005|\n",
      "| 44|    Trevor|   Carter| 38670|         1001|\n",
      "| 73|   William|  Preston|155225|         1003|\n",
      "| 39|     Linda|    Clark|186781|         1002|\n",
      "| 10|      Sean| Crawford|190000|         1006|\n",
      "| 30|   Stephen|    Smith|194791|         1001|\n",
      "| 75|     Julia|    Ramos|105000|         1006|\n",
      "| 59|     Kevin| Robinson|100924|         1005|\n",
      "| 69|    Ernest| Peterson|115993|         1005|\n",
      "| 65|   Deborah|   Martin| 67389|         1004|\n",
      "| 63|   Richard|  Sanford|136083|         1001|\n",
      "+---+----------+---------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check sample Data \n",
    "employeedf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b4f318-0d5f-4be1-b9df-7fe6b3b008dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV file into DataFrame\n",
    "departmentdf = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"department.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c4435b-dbdd-4890-9c0c-5b6e680005d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- department_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check Schema of DataFrame\n",
    "departmentdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "296c262a-a858-46a2-9bb3-38d212b52daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|department_id|department_name|\n",
      "+-------------+---------------+\n",
      "|         1005|          Sales|\n",
      "|         1002|       Finanace|\n",
      "|         1004|       Purchase|\n",
      "|         1001|     Operations|\n",
      "|         1006|      Marketing|\n",
      "|         1003|      Technoogy|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check sample Data \n",
    "departmentdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dc98254-6248-4cd6-af15-bb4b5a832171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+-------------+---------------+\n",
      "| id|first_name|last_name|salary|department_id|department_id|department_name|\n",
      "+---+----------+---------+------+-------------+-------------+---------------+\n",
      "| 45|     Kevin|   Duncan| 45210|         1003|         1003|      Technoogy|\n",
      "| 25|    Pamela| Matthews| 57944|         1005|         1005|          Sales|\n",
      "| 48|    Robert|    Lynch|117960|         1004|         1004|       Purchase|\n",
      "| 34|    Justin|     Dunn| 67992|         1003|         1003|      Technoogy|\n",
      "| 62|      Dale|    Hayes| 97662|         1005|         1005|          Sales|\n",
      "|  1|      Todd|   Wilson|110000|         1006|         1006|      Marketing|\n",
      "| 61|      Ryan|    Brown|120000|         1003|         1003|      Technoogy|\n",
      "| 21|   Stephen|    Berry|123617|         1002|         1002|       Finanace|\n",
      "| 13|     Julie|  Sanchez|210000|         1001|         1001|     Operations|\n",
      "| 55|   Michael|   Morris|106799|         1005|         1005|          Sales|\n",
      "| 44|    Trevor|   Carter| 38670|         1001|         1001|     Operations|\n",
      "| 73|   William|  Preston|155225|         1003|         1003|      Technoogy|\n",
      "| 39|     Linda|    Clark|186781|         1002|         1002|       Finanace|\n",
      "| 10|      Sean| Crawford|190000|         1006|         1006|      Marketing|\n",
      "| 30|   Stephen|    Smith|194791|         1001|         1001|     Operations|\n",
      "| 75|     Julia|    Ramos|105000|         1006|         1006|      Marketing|\n",
      "| 59|     Kevin| Robinson|100924|         1005|         1005|          Sales|\n",
      "| 69|    Ernest| Peterson|115993|         1005|         1005|          Sales|\n",
      "| 65|   Deborah|   Martin| 67389|         1004|         1004|       Purchase|\n",
      "| 63|   Richard|  Sanford|136083|         1001|         1001|     Operations|\n",
      "+---+----------+---------+------+-------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Solving Problem using PySpark \n",
    "# 1. Use this both tables and list all the employees woking in marketing department with highest to lowest salary order. \n",
    "\n",
    "joineddf = employeedf.join(departmentdf, employeedf.department_id == departmentdf.department_id,\"left\")\n",
    "joineddf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d16d14-c013-416c-9552-d95e0900d4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+\n",
      "|first_name|last_name|salary|\n",
      "+----------+---------+------+\n",
      "|      Sean| Crawford|190000|\n",
      "|  Danielle| Williams|120000|\n",
      "|      Todd|   Wilson|110000|\n",
      "|     Julia|    Ramos|105000|\n",
      "|      Eric|Zimmerman| 83093|\n",
      "|     Jason|    Olsen| 51937|\n",
      "|     Jason|  Burnett| 42525|\n",
      "|    Philip|Gillespie| 36424|\n",
      "+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "joineddf.select(\"first_name\",\"last_name\",\"salary\").where(\"department_name='Marketing'\").orderBy(desc(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c28f990b-7e88-4c88-bd36-ca17a83544c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are solving Same problem using Spark SQL \n",
    "# Creating Temp Table or HIVE table\n",
    "employeedf.createOrReplaceTempView(\"tmpEmployee\")\n",
    "departmentdf.createOrReplaceTempView(\"tmpDepartment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a48a300-9f44-4321-a138-942e6f1daf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+\n",
      "| id|first_name|last_name|salary|department_id|\n",
      "+---+----------+---------+------+-------------+\n",
      "| 45|     Kevin|   Duncan| 45210|         1003|\n",
      "| 25|    Pamela| Matthews| 57944|         1005|\n",
      "| 48|    Robert|    Lynch|117960|         1004|\n",
      "| 34|    Justin|     Dunn| 67992|         1003|\n",
      "| 62|      Dale|    Hayes| 97662|         1005|\n",
      "|  1|      Todd|   Wilson|110000|         1006|\n",
      "| 61|      Ryan|    Brown|120000|         1003|\n",
      "| 21|   Stephen|    Berry|123617|         1002|\n",
      "| 13|     Julie|  Sanchez|210000|         1001|\n",
      "| 55|   Michael|   Morris|106799|         1005|\n",
      "| 44|    Trevor|   Carter| 38670|         1001|\n",
      "| 73|   William|  Preston|155225|         1003|\n",
      "| 39|     Linda|    Clark|186781|         1002|\n",
      "| 10|      Sean| Crawford|190000|         1006|\n",
      "| 30|   Stephen|    Smith|194791|         1001|\n",
      "| 75|     Julia|    Ramos|105000|         1006|\n",
      "| 59|     Kevin| Robinson|100924|         1005|\n",
      "| 69|    Ernest| Peterson|115993|         1005|\n",
      "| 65|   Deborah|   Martin| 67389|         1004|\n",
      "| 63|   Richard|  Sanford|136083|         1001|\n",
      "+---+----------+---------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we have SQL Table and we can write SQL Query on top of that \n",
    "# For example by Select on table \n",
    "sqlContext.sql(\"SELECT * FROM tmpEmployee\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4ac25f9-cd26-44dc-9852-ee0fbae70fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|department_id|department_name|\n",
      "+-------------+---------------+\n",
      "|         1005|          Sales|\n",
      "|         1002|       Finanace|\n",
      "|         1004|       Purchase|\n",
      "|         1001|     Operations|\n",
      "|         1006|      Marketing|\n",
      "|         1003|      Technoogy|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM tmpDepartment\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33554293-3ecb-4c46-8991-be98b4c3ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+\n",
      "|first_name|last_name|salary|\n",
      "+----------+---------+------+\n",
      "|      Sean| Crawford|190000|\n",
      "|  Danielle| Williams|120000|\n",
      "|      Todd|   Wilson|110000|\n",
      "|     Julia|    Ramos|105000|\n",
      "|      Eric|Zimmerman| 83093|\n",
      "|     Jason|    Olsen| 51937|\n",
      "|     Jason|  Burnett| 42525|\n",
      "|    Philip|Gillespie| 36424|\n",
      "+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we will write query to get max salary for each employee \n",
    "# so we will use SQL Group by and SQL Order by functions \n",
    "sqlContext.sql(\"SELECT first_name, last_name, salary \\\n",
    "                       FROM tmpEmployee as emp \\\n",
    "                       LEFT OUTER JOIN tmpDepartment as department \\\n",
    "                       ON emp.department_id = department.department_id \\\n",
    "                       WHERE department.department_name = 'Marketing' \\\n",
    "                       ORDER BY salary DESC\").show(n=100)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
